# 大语言模型基础
## 分词与词向量
1. 正文分词难点和分词算法
2. jieba分词用法及原理
3. 词性标注-难点、算法
4. 句法分析-分类、分析工具
5. 词向量-工具、训练算法、代码实现

## 语言模型基础知识
1. Word2Vec
2. NLP三大特征抽取器（CNN/RNN/TF）
3. LLM为什么Decoder only架构

## LLM概念
1. 目前 主流的开源模型体系 有哪些？
2. prefix LM 和 causal LM 区别是什么？
3. 大模型LLM的 训练目标
4. 涌现能力是啥原因？
5.  大模型架构介绍
6. LLMs复读机问题
7. LLMs输入句子长度理论上可以无限长吗？
8. 什么情况用Bert模型，什么情况用LLaMA、ChatGLM类大模型，咋选？
9. 如何让大模型处理更长的文本？

## 提示词工程
### 提示词工程能解决什么问题
<font style="color:rgb(51, 51, 51);">1. 核心定位：提示词工程是用户意图与模型能力的桥梁</font>

<font style="color:rgb(51, 51, 51);">提示词工程（Prompt Engineering）是通过设计和优化输入指令（Prompt），引导大模型生成符合预期的输出结果。它解决的核心问题是”如何让模型理解用户需求并精准完成任务”，尤其是在模型本身不可修改（如闭源API调用）的场景下，提示词是开发者控制模型行为的核心工具。</font>

<font style="color:rgb(51, 51, 51);">2. 解决的关键问题</font>

<font style="color:rgb(51, 51, 51);">（1）任务定义模糊性</font>

+ **<font style="color:rgb(51, 51, 51);">问题</font>**<font style="color:rgb(51, 51, 51);">：用户需求可能不明确（如“写一篇关于AI的文章”）。</font>
+ **<font style="color:rgb(51, 51, 51);">解决</font>**<font style="color:rgb(51, 51, 51);">：通过提示词细化任务边界（如“以科普风格写一篇面向高中生的AI技术发展史，包含3个案例”）。</font>
+ **<font style="color:rgb(51, 51, 51);">场景</font>**<font style="color:rgb(51, 51, 51);">：内容生成、客服对话中避免开放式回答。</font>

<font style="color:rgb(51, 51, 51);">（2）输出格式控制</font>

+ **<font style="color:rgb(51, 51, 51);">问题</font>**<font style="color:rgb(51, 51, 51);">：模型输出可能不符合结构化要求（如JSON、表格、特定代码格式）。</font>
+ **<font style="color:rgb(51, 51, 51);">解决</font>**<font style="color:rgb(51, 51, 51);">：在提示词中明确格式（如“用Markdown表格列出5个新能源车的优缺点”）。</font>
+ **<font style="color:rgb(51, 51, 51);">场景</font>**<font style="color:rgb(51, 51, 51);">：</font><font style="color:rgb(51, 51, 51);">数据抽取</font><font style="color:rgb(51, 51, 51);">、API参数生成、自动化报告。</font>

<font style="color:rgb(51, 51, 51);">（3）领域知识适配</font>

+ **<font style="color:rgb(51, 51, 51);">问题</font>**<font style="color:rgb(51, 51, 51);">：通用模型缺乏垂直领域知识（如医疗、法律术语）。</font>
+ **<font style="color:rgb(51, 51, 51);">解决</font>**<font style="color:rgb(51, 51, 51);">：通过Few-shot Learning（示例引导）或上下文注入专业知识。</font>
+ **<font style="color:rgb(51, 51, 51);">场景</font>**<font style="color:rgb(51, 51, 51);">：医疗问答系统、法律文书生成。</font>

<font style="color:rgb(51, 51, 51);">（4）偏见与安全性控制</font>

+ **<font style="color:rgb(51, 51, 51);">问题</font>**<font style="color:rgb(51, 51, 51);">：模型可能生成有害、偏见或政治敏感内容。</font>
+ **<font style="color:rgb(51, 51, 51);">解决</font>**<font style="color:rgb(51, 51, 51);">：提示词中设置“安全护栏”（如“用中立客观的语言解释气候变化”）。</font>
+ **<font style="color:rgb(51, 51, 51);">场景</font>**<font style="color:rgb(51, 51, 51);">：社交媒体审核、教育内容生成。</font>

<font style="color:rgb(51, 51, 51);">（5）复杂任务拆解</font>

+ **<font style="color:rgb(51, 51, 51);">问题</font>**<font style="color:rgb(51, 51, 51);">：单一Prompt难以处理多步骤任务（如数据分析：爬取→清洗→可视化）。</font>
+ **<font style="color:rgb(51, 51, 51);">解决</font>**<font style="color:rgb(51, 51, 51);">：通过Chain-of-Thought（思维链）提示分阶段引导模型推理。</font>
+ **<font style="color:rgb(51, 51, 51);">场景</font>**<font style="color:rgb(51, 51, 51);">：代码生成、数学解题、决策支持系统。</font>

<font style="color:rgb(51, 51, 51);">3. 实际开发中的价值</font>

<font style="color:rgb(51, 51, 51);">（1）降低模型微调成本</font>

+ <font style="color:rgb(51, 51, 51);">无需重新训练模型即可适配新任务，节省算力和时间（如使用GPT-3处理不同行业客服需求）。</font>

<font style="color:rgb(51, 51, 51);">（2）提升用户体验</font>

+ <font style="color:rgb(51, 51, 51);">减少“反复调试”的挫败感（如通过优化提示词让AI绘图工具一次性生成符合要求的图像）。</font>

<font style="color:rgb(51, 51, 51);">（3）工程化扩展性</font>

+ <font style="color:rgb(51, 51, 51);">可构建提示词模板库、支持A/B测试不同Prompt效果，形成可复用的解决方案。</font>

<font style="color:rgb(51, 51, 51);">4. 回答示例</font>

<font style="color:rgb(51, 51, 51);">“提示词工程主要解决大模型应用中用户意图与模型输出之间的对齐问题。例如，当用户需要模型生成特定格式的数据报告时，通过结构化提示词明确内容框架和输出格式；在医疗咨询场景中，通过Few-shot示例注入专业术语，提升回答准确性。此外，它还能控制模型安全边界，避免生成有害内容。从工程角度看，优秀的提示词设计可以降低对模型微调的依赖，快速适配多样化需求，是提升产品体验和开发效率的关键手段。”</font>

<font style="color:rgb(51, 51, 51);">5. 加分项：结合开发经验</font>

+ <font style="color:rgb(51, 51, 51);">举例说明你曾用提示词工程解决的具体问题（如“在XX项目中，通过添加角色设定Prompt让客服机器人语气更友好，投诉率下降30%”）。</font>
+ <font style="color:rgb(51, 51, 51);">提及对新兴技术的关注（如Microsoft Guidance框架、LangChain中的Prompt模板工具）。</font>

<font style="color:rgb(51, 51, 51);">通过以上结构，既能体现理论深度，又能展示工程落地思维，符合大模型应用工程师的岗位要求。</font>

# 大语言模型架构
## Transformer模型
### 简述下Transformer基本原理
要理解的深一点。把这幅图能讲清楚。

![](https://cdn.nlark.com/yuque/0/2025/png/640636/1759716775038-b274f478-feeb-4a9f-91c0-5405952307bd.png)

### Transformer的并行计算与长序列处理瓶颈
### 为什么Transformer的架构需要多头注意力机制
### 为什么transformers需要位置编码
### transformer中，同一个词可以有不同的注意力权重吗
## 注意力机制


## 解码


## BERT


## 常见大模型
### Deepseek
1. <font style="color:rgb(31, 35, 40);">对最近的大模型关注是怎么样?deepseek架构介绍一下,和gpt有什么不同,GRPO算法介绍</font>
2. <font style="color:rgb(31, 35, 40);">deepseek与MHA跟其他的一些attention的算法上面的一些区别</font>

### <font style="color:rgb(31, 35, 40);">llama</font>
1. <font style="color:rgb(31, 35, 40);">gpt框架与llama框架解释一下</font>

## MoE
1. <font style="color:rgb(31, 35, 40);">为什么要用MOE架构嗯或者它亮点是什么</font>
2. <font style="color:rgb(31, 35, 40);">MOE架构那你实际上有去实践吗</font>

# 分布式训练
## 基础知识
+ 数据并行
+ 流水线并行
+ 张量并行
+ 序列并行
+ 多维度混合并行
+ 自动并行
+ MoE并行

## DeepSpeed
<font style="color:rgb(31, 35, 40);">deepspeed微调全部细节描述讲解,zero阶段之类的描述原理,accelarate怎么用</font>

## Megatron
# 有监督微调
## 理论
1. BitFit
2. Prefix Tuning
3. Prompt Tuning
4. P-Tuning
5. adapter-tuning
6. LoRA
    1. <font style="color:rgb(31, 35, 40);">qlora和lora的效果对比,区别在哪儿?怎么选择</font>
    2. <font style="color:rgb(31, 35, 40);">lora微调的时候r=8,或者16有什么区别?你是怎么确定用哪个的?</font>

## <font style="color:rgb(31, 35, 40);">怎么微调和数据采集,需要多大量的数据</font>
## 如果想要在某个模型基础上做全参数微调，究竟需要多少显存？
## 为什么SFT之后感觉LLM傻了?
## SFT 指令微调数据 如何构建?
## 领域模型Continue PreTrain 数据选取？
## 领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？
## 领域模型Continue PreTrain ，如何 让模型在预训练过程中就学习到更多的知识？
## 进行SFT操作的时候，基座模型选用Chat还是Base?
## 领域模型微调 指令 & 数据输入格式 要求？
## 领域模型微调 领域评测集 构建？
## <font style="color:rgb(31, 35, 40);">垂直领域模型微调,具体是基于什么业务场景,什么需求下开始的?为什么rag不能,要用微调?</font>
## 领域模型词表扩增是不是有必要的？
## 如何训练自己的大模型？
## 指令微调的好处？
## 预训练和微调哪个阶段注入知识的？
## 想让模型学习某个领域或行业的知识，是应该预训练还是应该微调？
## 多轮对话任务如何微调模型？
## 微调后的模型出现能力劣化，灾难性遗忘是怎么回事？
## 预训练和SFT操作有什么不同
## 样本量规模增大，训练出现OOM错
## 大模型LLM进行SFT 如何对样本进行优化？
## 模型参数迭代实验
## 为什么要增量预训练？
## 进行增量预训练需要做哪些准备工作？
## 增量预训练所用训练框架？
## 增量预训练数据选取思路有哪些？
## 增量预训练训练流程是怎么样？
# 推理
## 推理框架
+ vLLM
+ text_generation_inference
+ faster_transformer
+ trt_llm

## 推理优化技术
[https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/](https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/)

+ 理解LLM推理
    - 预填充阶段或处理输入
    -  解码阶段或生成输出
    - 批处理（Batching）
    - KV缓存
    - LLM内存需求
+ 模型并行化扩展LLM
    - Pipeline并行
    - Tensor并行
    -  Sequence并行
+ 注意力机制优化
    - 多头注意力（MHA）
    - 多查询注意力（MQA）
    - 分组注意力（GQA）
    - Flash attention
+ KV缓存的分页高效管理
+ 模型优化技术
    - 量化（Quantization）
    - 稀疏（Sparsity）
    - 蒸馏（Distillation）
+ 模型服务技术
    - 动态批处理（In-flight batching）
    - 预测推理（Speculative inference）

# 强化学习
## 强化学习原理
+ 策略梯度（pg）
+ 近端策略优化(ppo)

[https://www.cnblogs.com/xingzheai/p/15931681.html](https://www.cnblogs.com/xingzheai/p/15931681.html)

## RLHF
[https://zhuanlan.zhihu.com/p/677607581](https://zhuanlan.zhihu.com/p/677607581)

## 奖励模型需要和基础模型一致吗？
## RLHF 在实践过程中存在哪些不足？
## 如何解决 人工产生的偏好数据集成本较高，很难量产问题？
## 如何解决三个阶段的训练（SFT->RM->PPO）过程较长，更新迭代较慢问题？
## 如何解决 PPO 的训练过程同时存在4个模型（2训练，2推理），对计算资源的要求较高 问题？
## 基于人类反馈的强化学习流程
## 如何给LLM注入领域知识？
# RAG
[万字长文: 检索增强 LLM](https://mp.weixin.qq.com/s?__biz=MzA5NTQ2MDEyOA==&mid=2247484380&idx=1&sn=7b0b5dc3f76dd7a634ebb77df8697a24&chksm=90be4d93a7c9c485593b6a299d607bfbcc30f05ec691b85f1fb6cf81c51ffe863dbc34759be6&mpshare=1&scene=1&srcid=1204gaSWi0sA7clI6UZEYYL5&sharer_shareinfo=f728c72f50e0aee521fb1319eb3b82b0&sharer_shareinfo_first=f728c72f50e0aee521fb1319eb3b82b0#rd)

## RAG解决的问题
+ 长尾知识
+ 私有数据
+ 数据新鲜度
+ 来源验证和可解释性

## RAG关键模块
## 几种RAG的调用模式
![](https://cdn.nlark.com/yuque/0/2025/png/640636/1759668598952-9b665cd5-47cd-403d-9149-69fefb6a2ede.png)

## RAG VS SFT
## <font style="color:rgb(31, 35, 40);">rag里面的知识怎么结构化的?</font>
# Agent
视频：[从第一性原理看大模型Agent技术_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1mC4y1g7cT/?vd_source=89c53fe860e94063cf81563bb24c2072)

文章：[https://mp.weixin.qq.com/s/PL-QjlvVugUfmRD4g0P-qQ](https://mp.weixin.qq.com/s/PL-QjlvVugUfmRD4g0P-qQ)

## LLM Agent 有什么关键能力？
## 怎样构建基于 LLM 的 Agents？
## LLM Agents 有哪些类型？
## 是什么让Agent有了自制的能力？
# 大语言模型评估
## 大模型怎么评测？
## 大模型的 honest 原则是如何实现的？模型如何判断回答的知识是训练过的已知的知识，怎么训练这种能力？
##  如何衡量大模型水平？
## 大模型评估方法有哪些？
## 大模型评估工具有哪些？
# 大模型幻觉
## 什么是大模型幻觉？
## 为什么需要解决LLM的幻觉问题？
## 幻觉一定是有害的吗？
## 幻觉有哪些不同类型？
## 为什么LLM会产生幻觉？
## 如何度量幻觉？
## 如何缓解LLM幻觉？
## LLMs什么时候最容易产生幻觉？
# 大语言模型应用
## CoT
### 什么是思维链提示？
### 思维链提示本质是什么？
### 思维链提示 与 标准的提示学习方法有什么不同?
### 思维链提示 为什么可以提高语言模型的复杂推理能力?它的优势在哪里?
### 思维链提示 适用场景 有 哪些？
### 思维链提示 目前还存在哪些不足点？
### 思维链提示 对推动语言模型复杂推理能力研究有哪些启发和影响?
### 如何通过增加模型规模来获得语言模型强大的思路链推理能力的?这与模型获得的哪些能力有关?
### 可以在哪些其他方面应用“思路链提示”这一思路来提升语言模型的能力?
### 你认为关键的未来研究方向是什么?
## LangChain
### LangChain 包含哪些核心模块
LangChain 的提供了以下 6 种标准化、可扩展的接口并且可以外部集成的核心模块：

+ 模型输 入/输出（Model I/O）：与语言模型交互的接口；
+ 数据连接（Data connection）：与特定应用程序的数 据进行交互的接口；
+ 链（Chains）：用于复杂的应用的调用序列；
+ 智能体（Agents）：语言模型作为推理器决定要执行的动作序列；
+ 记忆（Memory）：用于链的多次运行之间持久化应用程序状态；
+ 回调 （Callbacks）：记录和流式传输任何链式组装的中间步骤。

### 一些核心概念
+ Components and Chains
+ Prompt Templates and Values
+ Example Selectors
+ Output Parsers
+ Indexes and Retrievers
+ Chat Message History
+ Agents and Toolkits

### 什么是 LangChain Agent?
### 什么是 LangChain model?
### LangChain 如何使用?
1. LangChain 如何调用 LLMs 生成回复？
2. LangChain 如何修改 提示模板？
3. LangChain 如何链接多个组件处理一个特定的下游任务？
4. LangChain 如何Embedding & vector store？

### LangChain知识问答实践
基于 LangChain 的知识问答系统框架如图所示。

![](https://cdn.nlark.com/yuque/0/2025/png/640636/1759669845385-82f50473-7d69-49a1-afa9-c4af7103542e.png)

# 架构设计面试题
## 如何评估一个 RAG 流水线的性能
<font style="color:rgb(51, 51, 51);">评估 RAG 流水线意味着你要看两个系统，它们各自要出色，并且要协同工作——检索和生成。首先，对于检索器，你需要评估它是否能针对查询返回正确的文档。这时，像 Precision@k、Recall@k 和平均倒数排名（MRR）这样的指标就大放异彩了。它们有助于确定相关文档在 top-k 结果中出现的频率，以及这些相关结果出现的早晚。</font>

<font style="color:rgb(51, 51, 51);">但这只是故事的一半。</font>

<font style="color:rgb(51, 51, 51);">生成组件需要在真实性方面进行评估——它是否会“幻觉化”，还是会基于检索到的数据保持脚踏实地？在这方面，像 FEVER 和 TruthfulQA 这样的数据集是很好的基准。你还要检查相关性，可以通过生成内容与原始用户查询之间的词汇重叠，或者使用语义相似性分数来衡量。</font>

<font style="color:rgb(51, 51, 51);">最后，将这些定量指标与人类评估和用户反馈循环结合起来，这对于理解细微差别至关重要——答案是否感觉有用、可信且表达清晰？</font>

## 在使用 RAG 构建的生成式问答系统中减少幻觉现象，你会如何着手
<font style="color:rgb(51, 51, 51);">在基于 RAG 的系统中减少幻觉现象，需要控制生成内容在检索文档中的“扎根”程度。第一步是优化检索器，确保它能够浮现出真正相关的段落——可以使用像 Contriever 或 ColBERT 这样的密集检索器，并在特定领域数据上进行微调。接下来，在生成器之前引入过滤层，使用重排序器或文档分类器来剔除检索到的低质量内容。</font>

<font style="color:rgb(51, 51, 51);">然后，在生成方面，应用受限解码技术（如复制机制或带有 top-p 限制的核采样），以防止模型编造未经支持的信息。在生成过程中整合引用或来源归属机制，也可以加强可追溯性，促使模型保持锚定。</font>

<font style="color:rgb(51, 51, 51);">最后，闭环操作：实施反馈感知训练，或者使用对比学习，通过惩罚与检索上下文偏离的输出来实现。这些措施共同缩小了检索与生成之间的差距，大幅减少了幻觉现象。</font>

## <font style="color:rgb(51, 51, 51);">客户希望在他们专有的数据集上微调一个大型语言模型，但 GPU 可用性有限，你会如何进行？</font>
<font style="color:rgb(51, 51, 51);">全参数微调在这里是不可行的——它内存占用大且计算成本高昂。相反，最好的选择是使用参数高效微调（PEFT）方法。从 LoRA（低秩适应）开始，它只训练一小部分参数，大幅减少资源使用。如果内存极度受限，转向 QLoRA，它将 LoRA 与量化（通常是 4 位）结合起来，允许在消费级 GPU 上进行微调。</font>

<font style="color:rgb(51, 51, 51);">确保冻结基础模型，只更新注入的适配器层。像 Hugging Face 的 PEFT 库这样的工具可以让这个过程无缝进行。并且记得密切监控性能；如果模型在下游任务中表现不佳，考虑选择性地解冻关键的 Transformer 块。</font>

## <font style="color:rgb(51, 51, 51);">设计一个可扩展的检索系统，能够处理数十亿文档上的多语言查询。</font>
<font style="color:rgb(51, 51, 51);">可扩展性和多语言性是一个棘手的组合。你首先使用像 LaBSE、mBERT 或 DistilmBERT-Multilingual 这样的模型构建密集向量索引，它们将跨语言的语义含义编码到共享的嵌入空间中。使用 Milvus、 FAISS 或 Weaviate 进行可扩展的向量索引，按文档语言或主题进行分片，以优化查询时间。</font>

<font style="color:rgb(51, 51, 51);">为了保持实时性能，预先计算并缓存高频查询向量。在推理时添加一个语言检测层，以调节查询嵌入管道。此外，考虑使用多语言交叉编码器对检索到的段落进行重排序，以提高精度。</font>

<font style="color:rgb(51, 51, 51);">最后，用户交互日志应该回流，以便使用多语言中的硬负样本进行对比学习，持续改进检索器。</font>

## <font style="color:rgb(51, 51, 51);">如何评估一个在法律文件上训练的大模型是否给出准确、可信的输出？</font>
你不仅想要准确率，你还想要在法律上站得住脚的输出。从 BLEU、ROUGE 或 BERTScore 这样的自动指标开始，但要明白它们只是触及表面。对于法律环境，优先考虑真实性和可解释性。使用包含事实陷阱或对抗性措辞的自定义评估集，测试模型是否“扎根”。

实施法律专业人士的人工审查。在你的系统中建立一个反馈循环，让法律专家可以标记模糊或不正确的生成内容，并利用这些数据进一步微调或对齐模型。

你还可以在生成过程中整合引用验证——引用的案例法或法规是否真的出现在检索到的内容中？如果没有，那就是披着法律术语的幻觉。

## 如何优化一个预计要处理 1000+ 并发用户的智能客服 AI 智能体的延迟？
<font style="color:rgb(51, 51, 51);">首先，在使用优化的 Transformer 库（如 vLLM 或 Triton）的 GPU 支持的设置上运行推理。这些支持连续批量处理，允许你在一次前向传递中为多个用户查询提供服务。</font>

<font style="color:rgb(51, 51, 51);">如果你还没有使用量化模型，那就切换过来——它们显著减少了计算时间。对于后端基础设施，使用异步消息队列，并启用自动扩展的 Kubernetes 进行水平扩展。</font>

<font style="color:rgb(51, 51, 51);">还要考虑为常见问题（例如“你的退款政策是什么？”）缓存输出，并在完整模型在后台完成时，使用早期退出解码或较小的精简模型进行首次响应。</font>

## <font style="color:rgb(51, 51, 51);">给定一个检索系统，它对小众生物医学查询返回不相关的文档，你会怎么做？</font>
不相关性可能源于通用嵌入。生物医学查询需要专门的理解，所以首先将基础模型替换为像 BioBERT 或 SciBERT 这样的模型，它们是在领域语料库上预训练的。

在领域内查询 - 文档对上微调检索器，这有助于使其语义空间与生物医学语言对齐。在训练期间纳入硬负样本（看起来相似但错误的文档），以加强对比学习。

最后，使用在生物医学问答上微调的交叉编码器进行重排序，以提高 top-k 精度。这样，即使你的初始检索有噪声，你的顶部结果也能保持高度相关。

## 设计一个持续改进已部署的 AI 大模型应用客户支持模型的流水线
<font style="color:rgb(51, 51, 51);">流水线从真实世界的反馈开始。捕获每一次客户互动，并标记那些被评为差或升级到人工智能体的互动。将这些作为微调数据，要么强化好的行为，要么缓解失败案例。</font>

<font style="color:rgb(51, 51, 51);">实施人工参与的验证系统，对标记的生成内容进行审查和纠正，并将这些纠正纳入每周或每月的更新周期。如果合适，使用人类反馈强化学习（RLHF），特别是要对齐语气和礼貌。</font>

<font style="color:rgb(51, 51, 51);">最后，设置监控仪表板，跟踪延迟、幻觉频率和用户满意度。如果任何一项下降，触发重新训练作业或回滚逻辑，以恢复到稳定的模型。</font>

## <font style="color:rgb(51, 51, 51);">如何处理一个多模态大模型的评估，该模型以图像和文本作为输入并生成标题？</font>
<font style="color:rgb(51, 51, 51);">首先，使用 BLEU、METEOR 和 CIDEr 等标准指标评估文本输出。但不要止步于此——这些指标只评估流畅性和表面级别的正确性。对于更深层次的语义相关性，使用 SPICE（查看场景图相似性）或 CLIPScore，后者通过嵌入测量图像和标题之间的对齐情况。</font>

<font style="color:rgb(51, 51, 51);">为了捕捉边缘情况（例如，讽刺、否定），包括人工评估者，他们根据相关性、创造力和语气对输出进行评分。在某些情况下，训练分类器以检测幻觉元素——比如说，如果标题中提到狗，而图像中没有狗。</font>

<font style="color:rgb(51, 51, 51);">此外，将图像 - 问题对作为输入，并通过视觉问答（VQA）指标进行评估，如果你的模型支持对视觉内容进行交互式查询的话。</font>



